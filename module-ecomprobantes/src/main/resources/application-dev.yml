spring:
  r2dbc:
    url: r2dbc:postgresql://127.0.0.1:5432/erp_tlm_2021
    username: postgres
    password: 12345
    pool:
      enabled: true
      initial-size: 5
      max-size: 20
      max-idle-time: 30m
      max-life-time: 60m
      validation-query: SELECT 1
    properties:
      timezone: America/Lima
      application-name: module-ecomprobantes
      connect-timeout: 10000
      socket-timeout: 0
      tcp-keep-alive: true
  # ✅ RESILIENCE4J - CONFIGURACIÓN COMPLETA
  resilience4j:
    circuitbreaker:
      instances:
        comprobante-generation:
          failure-rate-threshold: 50
          minimum-number-of-calls: 5
          sliding-window-size: 10
          wait-duration-in-open-state: 30s
          permitted-number-of-calls-in-half-open-state: 3
          automatic-transition-from-open-to-half-open-enabled: true
          record-exceptions:
            - java.io.IOException
            - java.util.concurrent.TimeoutException
            - org.springframework.web.reactive.function.client.WebClientException
            - java.sql.SQLException
        kafka-producer:
          failure-rate-threshold: 60
          minimum-number-of-calls: 3
          sliding-window-size: 8
          wait-duration-in-open-state: 15s
          permitted-number-of-calls-in-half-open-state: 2
          record-exceptions:
            - org.apache.kafka.common.errors.TimeoutException
            - org.apache.kafka.common.errors.NetworkException
            - org.apache.kafka.common.errors.RetriableException
        kafka-consumer:
          failure-rate-threshold: 70
          minimum-number-of-calls: 5
          sliding-window-size: 10
          wait-duration-in-open-state: 20s
          permitted-number-of-calls-in-half-open-state: 2
    ratelimiter:
      instances:
        comprobante-processing:
          limit-for-period: 50
          limit-refresh-period: 60s
          timeout-duration: 5s
          register-health-indicator: true
        kafka-events:
          limit-for-period: 100
          limit-refresh-period: 60s
          timeout-duration: 3s
    bulkhead:
      instances:
        comprobante-service:
          max-concurrent-calls: 10
          max-wait-duration: 5s
        kafka-processing:
          max-concurrent-calls: 20
          max-wait-duration: 3s
    timelimiter:
      instances:
        comprobante-timeout:
          timeout-duration: 45s
          cancel-running-future: true
        kafka-timeout:
          timeout-duration: 30s
          cancel-running-future: true
  kafka:
    bootstrap-servers: 127.0.0.1:9092
    properties:
      auto.create.topics.enabled: true
      security:
        protocol: PLAINTEXT
      schema.registry.url: http://127.0.0.1:8081
    consumer:
      group-id: comprobantes-group
      auto-offset-reset: latest #earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      properties:
        schema.registry.url: http://127.0.0.1:8081
        auto.registry.schemas: true
        max.partition.fetch.bytes: 10485760
        specific.avro.reader: true
        # ✅ CONFIGURACIÓN DE BACKPRESSURE
        max.poll.records: 50
        max.poll.interval.ms: 300000
        session.timeout.ms: 30000
        heartbeat.interval.ms: 10000
        fetch.min.bytes: 1024
        fetch.max.wait.ms: 5000
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      properties:
        schema.registry.url: http://127.0.0.1:8081
        auto.registry.schemas: true
        use.latest.version: true
        specific.avro.reader: true
        # ✅ CONFIGURACIÓN DE PRODUCER RESILIENTE
        acks: all
        retries: 3
        retry.backoff.ms: 1000
        enable.idempotence: true
        max.in.flight.requests.per.connection: 1
        compression.type: snappy
        linger.ms: 10
        batch.size: 65536
        buffer.memory: 33554432
        request.timeout.ms: 30000
        delivery.timeout.ms: 120000

# ✅ CONFIGURACIÓN DE BACKPRESSURE Y BUFFERS
app:
  kafka:
    consumer:
      backpressure:
        buffer-size: 1000
        overflow-strategy: BUFFER
        prefetch: 50
      processing:
        parallelism: 10
        max-concurrency: 20
    producer:
      backpressure:
        buffer-size: 500
        overflow-strategy: DROP_LATEST
      retry:
        max-attempts: 3
        backoff-delay: 1000ms
  comprobante:
    processing:
      timeout: 45s
      max-retries: 3
      batch-size: 20

# ✅ CONFIGURACIÓN DE LOGGING
logging:
  level:
    com.walrex.module_ecomprobantes.infrastructure.adapters.outbound.persistence: DEBUG
    org.springframework.data.r2dbc: DEBUG
    io.r2dbc.postgresql.QUERY: DEBUG
    io.r2dbc.postgresql.PARAM: DEBUG
    reactor.netty: INFO
    org.springframework.transaction: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level [%X{correlationId}] %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level [%X{correlationId}] %logger{36} - %msg%n"

# ✅ CONFIGURACIÓN DE AUDITORÍA
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
  metrics:
    export:
      prometheus:
        enabled: true
    tags:
      application: module-ecomprobantes

lycet:
  api:
    base-url: http://localhost:8880/api/v1
    endpoint: /despatch/send
    timeout: 30
    token: EXnPrun0IjhqwyZaNSWLZpeJ9y1ktZOJ
